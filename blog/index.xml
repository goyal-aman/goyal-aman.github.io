<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Blog on Aman Goyal</title><link>https://goyal-aman.github.io/blog/</link><description>Recent content in Blog on Aman Goyal</description><generator>Hugo</generator><language>en-US</language><copyright>Copyright © 2025, Aman Goyal.</copyright><lastBuildDate>Tue, 18 Nov 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://goyal-aman.github.io/blog/index.xml" rel="self" type="application/rss+xml"/><item><title>Understanding Constants in Go: Typed vs. Untyped (Kinds)</title><link>https://goyal-aman.github.io/understanding-constants-in-go-typed-vs.-untyped-kinds/</link><pubDate>Tue, 18 Nov 2025 00:00:00 +0000</pubDate><guid>https://goyal-aman.github.io/understanding-constants-in-go-typed-vs.-untyped-kinds/</guid><description>&lt;hr&gt;
&lt;h1 id="understanding-constants-in-go-typed-vs-untyped-kinds"&gt;Understanding Constants in Go: Typed vs. Untyped (Kinds)&lt;/h1&gt;
&lt;p&gt;​In Go, constants are immutable values evaluated entirely at compile time. A crucial concept for moving from beginner to intermediate Go programmer is understanding the difference between &lt;em&gt;typed&lt;/em&gt; and &lt;em&gt;untyped&lt;/em&gt; constants.&lt;/p&gt;
&lt;h2 id="1-untyped-constants-the-default-kind"&gt;1. Untyped Constants (The Default &amp;ldquo;Kind&amp;rdquo;)&lt;/h2&gt;
&lt;p&gt;​By default, any constant you declare without an explicit type is &lt;strong&gt;untyped&lt;/strong&gt;. These constants don&amp;rsquo;t adhere to Go&amp;rsquo;s strict type system initially; instead, they possess a generic classification known as a &lt;strong&gt;&amp;ldquo;kind&amp;rdquo;&lt;/strong&gt; (e.g., &lt;code&gt;untyped integer&lt;/code&gt;, &lt;code&gt;untyped float&lt;/code&gt;, &lt;code&gt;untyped string&lt;/code&gt;).&lt;/p&gt;</description></item><item><title>A Developer's Guide to Event-Driven Architecture with Kafka</title><link>https://goyal-aman.github.io/a-developers-guide-to-event-driven-architecture-with-kafka/</link><pubDate>Sun, 16 Nov 2025 00:00:00 +0000</pubDate><guid>https://goyal-aman.github.io/a-developers-guide-to-event-driven-architecture-with-kafka/</guid><description>&lt;hr&gt;
&lt;pre&gt;&lt;code&gt;# Unpacking Event-Driven Systems: A Journey Through Kafka, Coupling, and Collaboration

I've recently been reading &amp;quot;Designing Event-Driven Systems&amp;quot; by Ben Stopford (a book from Confluent), and it has crystallized many concepts about how modern, scalable systems are built. This post is a summary of my key takeaways, exploring what Kafka truly is, how services communicate, and the powerful patterns that emerge in an event-driven world.

## What is Kafka? (And What It Isn't)

It's easy to pigeonhole new technology by comparing it to what we already know. Kafka often gets compared to two familiar tools: Enterprise Service Buses (ESBs) and Databases. While it shares some characteristics with both, Kafka is fundamentally a **streaming platform**, a different beast altogether.

### Kafka vs. Enterprise Service Bus (ESB)

Like an ESB, Kafka is great at moving data between different systems. It can pull from a wide variety of sources, transform data, and push it to many destinations. But the similarities end there.

* **Architecture:** Traditional ESBs are often centralized, monolithic systems. Scaling them beyond a single machine is difficult and often not a core design feature. Kafka, on the other hand, is decentralized and designed for horizontal scalability from the ground up.
* **Philosophy:** ESBs often follow a &amp;quot;smart pipes, dumb endpoints&amp;quot; model. The central bus contains all the business logic, and a central team manages it. This creates a bottleneck, slowing down changes. Kafka flips this to &amp;quot;dumb pipes, smart endpoints.&amp;quot; Kafka itself is just a resilient, scalable log. The business logic lives in the services that produce and consume data, allowing for decentralized ownership and faster development cycles.

### Kafka vs. Database

Like a database, Kafka offers durable storage, a query language (KSQL), and even support for transactions. But its purpose is different.

Databases are optimized for storing **data at rest**. They excel at complex queries and managing the current state of information. Kafka is optimized for **data in motion**. It's designed to handle continuous, high-volume streams of events, making it the backbone for real-time applications.

## The Core of Kafka: The Distributed Log

So, what makes Kafka so powerful? It all comes down to its core abstraction: a partitioned, replayable, append-only log.

1. **Append-Only Log:** Kafka stores messages sequentially in what it calls a &amp;quot;topic.&amp;quot; Because both reads and writes are sequential disk operations, they are incredibly fast and efficient, allowing for batching, caching, and prefetching.
2. **Scalability:** A topic is broken down into partitions. These partitions can be distributed and replicated across many machines. Need more throughput? Just add more machines to the cluster and rebalance the partitions. This architecture makes it virtually impossible to hit a scaling limit.
3. **Ordering Guarantees:** Kafka provides a strict ordering guarantee for messages *within a single partition*. If you need global ordering across all messages (which is rare), you can use a topic with a single partition, but this will limit your throughput to what a single machine can handle.
4. **Data Retention &amp;amp; Compacted Topics:** By default, Kafka topics retain data for a set period (e.g., two weeks). But what if you want to keep the latest value for every key indefinitely? For this, Kafka has **Compacted Topics**. In a compacted topic, each message has a key. When a new message arrives with an existing key, the old version is eventually removed. This gives you a powerful pattern: a regular topic can serve as a complete, auditable changelog (every version of an event), while a compacted topic can provide a snapshot of the latest state.

## The Language of Services: Commands, Queries, and Events

In any distributed system, services need to talk to each other. This communication generally falls into three categories:

* **Commands:** A request for another service to perform an action that changes the system's state. Think of it as a direct order: &amp;quot;Process this payment!&amp;quot; This is your classic request/response model.
* **Queries:** A request to look something up without changing any state. For example, &amp;quot;Get user details for ID 123.&amp;quot;
* **Events:** These are notifications or facts about something that has already happened. They are one-way messages, like an announcement: &amp;quot;An order was placed.&amp;quot; Events are the foundation of loosely coupled systems.

## The Power of Loose Coupling

&amp;quot;Loose coupling&amp;quot; is a term we hear a lot, but what does it mean in practice? It's a measure of how much a change in one service will impact another.

Loosely coupled systems are not a silver bullet. Tightly coupled communication (like a direct request/response call) is perfectly fine for services where the contract is stable and changes are rare. But for systems that need to evolve, loose coupling is essential. It shields services from the ripple effect of changes in their dependencies.

Events are the key enabler of this. Let's see how.

### Events for Notification: Reversing the Burden of Responsibility

Imagine a traditional e-commerce system. When a user places an order, the `Order Service` is responsible for everything that happens next. It has to call the `Inventory Service` to reserve stock, the `Notification Service` to send an email, and the `Shipping Service` to prepare for delivery.

![Traditional Request/Response Model](/images/Designing%20Event%20Driven%20System/Screenshot_2025-11-16_at_2.06.25_PM.png)

What happens when a new `Dynamic Pricing Service` needs to know when an order is placed? You have to go back and modify the `Order Service` to add another call.

In an event-driven model, this responsibility is reversed. The `Order Service` simply publishes an `OrderPlaced` event to a Kafka topic. It doesn't know or care who is listening.

![Event-Driven Notification](/images/Designing%20Event%20Driven%20System/Screenshot_2025-11-16_at_2.34.53_PM.png)

Now, the Inventory, Notification, and Shipping services simply subscribe to this event stream and react accordingly. When the new `Dynamic Pricing Service` comes along, it can just plug into the existing stream without anyone having to change the `Order Service`. This &amp;quot;pluggability&amp;quot; is a superpower for large, evolving systems.

### Events for State Transfer

Another powerful use of events is to replicate state between services. Instead of the `Shipping Service` making a direct RPC call to the `Customer Service` every time it needs a customer's address, it can subscribe to a stream of `CustomerUpdated` events.

![Event-Driven State Transfer](/images/Designing%20Event%20Driven%20System/Screenshot_2025-11-16_at_2.39.15_PM.png)

The `Shipping Service` can then maintain its own local copy of customer data, in a format that is optimized for its own needs. This makes the `Shipping Service` more resilient (it can function even if the `Customer Service` is down) and more performant (it's reading from its own database).

## Orchestration vs. Choreography: Who's in Charge?

This leads us to two overarching patterns for managing workflows that span multiple services: Orchestration and Choreography.

### Orchestration: The Conductor

In an orchestrated system, a single, central service acts as a conductor. It controls the entire workflow, telling each service what to do and when.

![Orchestrated System](/images/Designing%20Event%20Driven%20System/Screenshot_2025-11-16_at_3.13.18_PM.png)

* **Pros:** The entire workflow is defined in one place. This makes it easy to understand, reason about, and debug. The logic is explicit.
* **Cons:** The orchestrator can become a central bottleneck and a single point of failure. It creates tight coupling; the orchestrator needs to know about every service it commands.

### Choreography: The Dancers

In a choreographed system, there is no central conductor. Each service knows its own small part of the process. It listens for events from other services, does its work, and then emits its own events.

![Choreographed System](/images/Designing%20Event%20Driven%20System/Screenshot_2025-11-16_at_2.56.12_PM.png)

* **Pros:** This is the epitome of loose coupling and pluggability. Services are independent and can be developed, deployed, and scaled separately. The system is highly resilient.
* **Cons:** The overall workflow is not defined in any single place. It's an emergent property of the system, which can make it difficult to understand and monitor the end-to-end process.

## Finding the Right Balance

No system is purely one or the other. The reality is that most complex systems use a mix of approaches.

Within a single team or a bounded context, services might use a mix of request/response and event-driven communication. However, when communicating *between* different teams or departments working on independent domains, event-driven communication becomes the standard.

![Hybrid Approach](/images/Designing%20Event%20Driven%20System/Screenshot_2025-11-16_at_3.14.41_PM.png)

This allows each department to evolve its internal services freely while maintaining a stable, loosely coupled contract with the rest of the organization.

By understanding these fundamental patterns, we can make more informed decisions about how to design systems that are not only powerful and scalable but also resilient and adaptable to the inevitable changes of the future.
&lt;/code&gt;&lt;/pre&gt;</description></item><item><title>The Long-Tail Problem: Where Relational Databases Start to Creak</title><link>https://goyal-aman.github.io/the-long-tail-problem-where-relational-databases-start-to-creak/</link><pubDate>Mon, 10 Nov 2025 00:00:00 +0000</pubDate><guid>https://goyal-aman.github.io/the-long-tail-problem-where-relational-databases-start-to-creak/</guid><description>&lt;hr&gt;
&lt;h3 id="why-relational-databases-struggle-with-long-tail-data"&gt;Why Relational Databases Struggle with Long-Tail Data?&lt;/h3&gt;
&lt;p&gt;Most systems have a few popular records that get accessed all the time — and millions of others that are rarely touched. This pattern is called the &lt;strong&gt;long tail&lt;/strong&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-shell" data-lang="shell"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;Popularity
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;│&lt;span class="se"&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="se"&gt;&lt;/span&gt;│ &lt;span class="p"&gt;|&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;│ &lt;span class="p"&gt;|&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;│ &lt;span class="p"&gt;|&lt;/span&gt;____________________
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;│
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;└───────────────────────────────▶
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;Head &lt;span class="o"&gt;(&lt;/span&gt;popular&lt;span class="o"&gt;)&lt;/span&gt; Tail &lt;span class="o"&gt;(&lt;/span&gt;rare&lt;span class="o"&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Relational databases (like MySQL or PostgreSQL) use &lt;strong&gt;B-tree indexes&lt;/strong&gt; to find rows quickly.&lt;br&gt;
They work great when most queries hit the same small set of data — the “head.”&lt;br&gt;
But when the dataset grows huge and queries become random, indexes get so large that they no longer fit in memory.&lt;/p&gt;</description></item><item><title>Low-Cost, Zero-Ops Analytics at Scale</title><link>https://goyal-aman.github.io/low-cost-zero-ops-analytics-at-scale/</link><pubDate>Wed, 01 Oct 2025 00:00:00 +0000</pubDate><guid>https://goyal-aman.github.io/low-cost-zero-ops-analytics-at-scale/</guid><description>&lt;hr&gt;
&lt;p&gt;One of the early challenges our product teams had was visibility — not having a clear view of how users interact with our product or what their experience looks like. This made it hard for them to plan what to improve next.&lt;/p&gt;
&lt;p&gt;We’re a small, independent team within a fast-growing financial technology arm of a large enterprise exploring new initiatives. While we operate autonomously, all security standards and org-level policies still apply to us. This means we get the freedom to experiment, but the solution has to be secure and compliant from day one.&lt;/p&gt;</description></item><item><title>[One Paper Later] On-demand Container Loading in AWS Lambda</title><link>https://goyal-aman.github.io/one-paper-later-on-demand-container-loading-in-aws-lambda/</link><pubDate>Mon, 07 Apr 2025 00:00:00 +0000</pubDate><guid>https://goyal-aman.github.io/one-paper-later-on-demand-container-loading-in-aws-lambda/</guid><description>&lt;hr&gt;
&lt;p&gt;You can also listen to AI generated discussion&lt;/p&gt;
&lt;iframe style="border-radius:12px" src="https://open.spotify.com/embed/episode/0IxfiKRMdnSIcDIMxChsd7?utm_source=generator" width="100%" height="152" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture" loading="lazy"&gt;&lt;/iframe&gt;
&lt;hr&gt;
&lt;h1 id="overview"&gt;Overview&lt;/h1&gt;
&lt;p&gt;AWS released this paper &lt;a href="https://www.usenix.org/system/files/atc23-brooker.pdf"&gt;On-demand Container Loading in AWS Lambda&lt;/a&gt; which discusses how they were able to scale their Lambda offering to support container images upto &lt;strong&gt;10 GiB&lt;/strong&gt; from originail &lt;strong&gt;250 Mib&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Originally, users had to ZIP their code and upload it to S3 to run on Lambda. For each new invocation (especially after a cold start), AWS would spin up a new lightweight VM, pull the ZIP file, and execute it. This worked well because AWS’s global backbone network is fast and 250 MiB is relatively small, keeping cold-start times low (typically ~50ms).&lt;/p&gt;</description></item><item><title>DocumentDB Load Balancing: A Key Learning from Our Load Testing</title><link>https://goyal-aman.github.io/documentdb-load-balancing-a-key-learning-from-our-load-testing/</link><pubDate>Wed, 26 Mar 2025 00:00:00 +0000</pubDate><guid>https://goyal-aman.github.io/documentdb-load-balancing-a-key-learning-from-our-load-testing/</guid><description>&lt;hr&gt;
&lt;h1 id="tldr"&gt;TLDR;&lt;/h1&gt;
&lt;p&gt;API Gateway can provide caching, logging auth and load balancer distributes traffic between 2 or more servers for high-availability and horizontal scaling.&lt;/p&gt;
&lt;p&gt;Both load balancer and Api gateways are used between web clients and web servers. But they have served different purpose, that is to say, they are not interchangeable.&lt;/p&gt;
&lt;h1 id="load-balancers"&gt;Load Balancers&lt;/h1&gt;
&lt;p&gt;Core function of load balancer is to distribute traffic. They receive traffic from web client’s and distribute them between 2 or more web servers.&lt;/p&gt;</description></item><item><title>Distributed Locks - Naive</title><link>https://goyal-aman.github.io/distributed-locks-naive/</link><pubDate>Mon, 30 Dec 2024 00:00:00 +0000</pubDate><guid>https://goyal-aman.github.io/distributed-locks-naive/</guid><description>&lt;hr&gt;
&lt;p&gt;Locks are used by processes to acquire exclusive access to resource which are shared among many processes. Exclusive access is required to prevent race conditions which hard debug and nightmare to detect.&lt;/p&gt;
&lt;p&gt;Imagine scenario of an admin is updating an email group by uploading a file. The process works like this:&lt;/p&gt;
&lt;p&gt;All existing users in the group are removed.
New users listed in the file are added in batches (e.g., 10,000 at a time).
Seems straightforward, right? But now, consider what happens if another file is uploaded while the first one is still being processed.&lt;/p&gt;</description></item><item><title>Understanding OLAP and OLTP</title><link>https://goyal-aman.github.io/understanding-olap-and-oltp/</link><pubDate>Mon, 23 Dec 2024 00:00:00 +0000</pubDate><guid>https://goyal-aman.github.io/understanding-olap-and-oltp/</guid><description>&lt;hr&gt;
&lt;h1 id="tldr"&gt;TLDR;&lt;/h1&gt;
&lt;p&gt;Any database falls into one of two category OLAP or OLTP — depending on the access pattern for which it is optimised&lt;/p&gt;
&lt;h1 id="key-differences-olap-vs-oltp"&gt;Key differences: OLAP vs. OLTP&lt;/h1&gt;
&lt;p&gt;The primary purpose of online analytical processing (OLAP) is to analyse aggregated data, while the primary purpose of online transaction processing (OLTP) is to process database transactions.&lt;/p&gt;
&lt;p&gt;You use OLAP systems to generate reports, perform complex data analysis, and identify trends. In contrast, you use OLTP systems to process orders, update inventory, and manage customer accounts.&lt;/p&gt;</description></item><item><title>Load Balancer vs. API Gateway: Understanding the Differences</title><link>https://goyal-aman.github.io/load-balancer-vs.-api-gateway-understanding-the-differences/</link><pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><guid>https://goyal-aman.github.io/load-balancer-vs.-api-gateway-understanding-the-differences/</guid><description>&lt;hr&gt;
&lt;h1 id="tldr"&gt;TLDR;&lt;/h1&gt;
&lt;p&gt;API Gateway can provide caching, logging auth and load balancer distributes traffic between 2 or more servers for high-availability and horizontal scaling.&lt;/p&gt;
&lt;p&gt;Both load balancer and Api gateways are used between web clients and web servers. But they have served different purpose, that is to say, they are not interchangeable.&lt;/p&gt;
&lt;h1 id="load-balancers"&gt;Load Balancers&lt;/h1&gt;
&lt;p&gt;&lt;img src="https://goyal-aman.github.io/images/load_balancer.png" alt="load-balancer"&gt;
Core function of load balancer is to distribute traffic. They receive traffic from web client’s and distribute them between 2 or more web servers.&lt;/p&gt;</description></item><item><title>Storing Values within Index</title><link>https://goyal-aman.github.io/storing-values-within-index/</link><pubDate>Mon, 09 Dec 2024 00:00:00 +0000</pubDate><guid>https://goyal-aman.github.io/storing-values-within-index/</guid><description>&lt;hr&gt;
&lt;p&gt;Relational databases can have one primary index and any number of secondary indexes. When queries uses indexes they use keys in the index to find values. There are two ways to have values&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Store actual row in index&lt;/li&gt;
&lt;li&gt;Store reference to rows in index&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Storing references to rows in index is a good when there are any secondary indexes. In this way when a value needs to be updated in row, it can be updated in one place and all the indexes can refer to that one value. Also transactional guarantees are easy to implement in this case. However, challenges may arrive when size of updated row is much larger then original row size that it cannot fit in its current heap location, in which case, row need to move to new location in heap. This requires either updating references in all secondary indexes to new location or leaving a forwarding pointer behind. In normal cases, however, hopping from indexes to heap for reads is too much of performance penalty.&lt;/p&gt;</description></item><item><title>Databases: Memory and Disks</title><link>https://goyal-aman.github.io/databases-memory-and-disks/</link><pubDate>Mon, 02 Dec 2024 00:00:00 +0000</pubDate><guid>https://goyal-aman.github.io/databases-memory-and-disks/</guid><description>&lt;hr&gt;
&lt;p&gt;Most databases rely on disks and SSD’s to store both data and data structures like table, rows, indexes. There are primarily two reasons for this: disk’s and SSD’s are persistent (or durable) that means data is not lost in case of power loss and they are much cheaper than ram for per Gb cost. Relying on persistent storage devices though comes with challenges. Data in memory needs to be encoded into certain format before it can be written on to them which is slow and CPU intensive.&lt;/p&gt;</description></item></channel></rss>